{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DeBerta-phase",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1FGp4_WpczNoSvFOP_nF_Nt2IqiTaX63f",
      "authorship_tag": "ABX9TyNb46228/yIYpG1NBzdEEde",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d8db1f91cda04c9d8b98cfe01aa51739": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_45f25b300db64d8e9929e0c622634f05",
              "IPY_MODEL_6576f9812d5a4874b3841ba16841006a",
              "IPY_MODEL_481106f273be4f4ba3ddec2ccaee99c2"
            ],
            "layout": "IPY_MODEL_f3446fad150744a3ac93c699db10d3c9"
          }
        },
        "45f25b300db64d8e9929e0c622634f05": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_71b68985043741d88b3e9697d641f8c2",
            "placeholder": "​",
            "style": "IPY_MODEL_4f82b1f5f05f4d0db94459b56ccbe2bf",
            "value": "100%"
          }
        },
        "6576f9812d5a4874b3841ba16841006a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_446ffbbb92ec4332bdb556f761350c2e",
            "max": 136,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f4ce147f6a7046d2a2d5eb7017963d00",
            "value": 136
          }
        },
        "481106f273be4f4ba3ddec2ccaee99c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_45147e40eae84068847dc721e0615700",
            "placeholder": "​",
            "style": "IPY_MODEL_8a163542584541bc87fcc24962845078",
            "value": " 136/136 [00:00&lt;00:00, 1648.88it/s]"
          }
        },
        "f3446fad150744a3ac93c699db10d3c9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "71b68985043741d88b3e9697d641f8c2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4f82b1f5f05f4d0db94459b56ccbe2bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "446ffbbb92ec4332bdb556f761350c2e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f4ce147f6a7046d2a2d5eb7017963d00": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "45147e40eae84068847dc721e0615700": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8a163542584541bc87fcc24962845078": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e881d10db4564725bea065433ac8bf19": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c2c664a5ec4d45928438da5b5c0ae6d9",
              "IPY_MODEL_8133e18115a34b3e8580a73ab4e58d0a",
              "IPY_MODEL_cf54968193024fd6b382a18381700a05"
            ],
            "layout": "IPY_MODEL_d294d55ed23c45fdb17c0fa7869e04aa"
          }
        },
        "c2c664a5ec4d45928438da5b5c0ae6d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cf0ca9e7e4e64c7a8d0ed949e6f0fc09",
            "placeholder": "​",
            "style": "IPY_MODEL_44a9f8c696d44f3ea73744e8b8b7f2a4",
            "value": "100%"
          }
        },
        "8133e18115a34b3e8580a73ab4e58d0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_84174fe4dbeb4b519f5d166c75c86eef",
            "max": 36473,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b1022f656b124b349a8c83b462d72170",
            "value": 36473
          }
        },
        "cf54968193024fd6b382a18381700a05": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bc768533ff9448119b9eb65154b1b2b1",
            "placeholder": "​",
            "style": "IPY_MODEL_daff355e2b8749059346592ec7e17c10",
            "value": " 36473/36473 [00:07&lt;00:00, 5186.80it/s]"
          }
        },
        "d294d55ed23c45fdb17c0fa7869e04aa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cf0ca9e7e4e64c7a8d0ed949e6f0fc09": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "44a9f8c696d44f3ea73744e8b8b7f2a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "84174fe4dbeb4b519f5d166c75c86eef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b1022f656b124b349a8c83b462d72170": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bc768533ff9448119b9eb65154b1b2b1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "daff355e2b8749059346592ec7e17c10": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "34293e2f302f4592802e0c572115a40d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3f57a1626a4f4a8b97e4b55a663fcd67",
              "IPY_MODEL_ea0baf8532dd4115bbd7007d1ee8484c",
              "IPY_MODEL_54d68b009b634f20965fa50c2d897cce"
            ],
            "layout": "IPY_MODEL_c2d79143086441fd999435085d96f2e9"
          }
        },
        "3f57a1626a4f4a8b97e4b55a663fcd67": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_077b83ef7d95450fba0d390b41d9f0fa",
            "placeholder": "​",
            "style": "IPY_MODEL_9ad4a57712664c11b350036a46c7836c",
            "value": "100%"
          }
        },
        "ea0baf8532dd4115bbd7007d1ee8484c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_53daf011f51b4111b0b81b528c1da1a3",
            "max": 36473,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_09395ab727904696b073d4ecb434f476",
            "value": 36473
          }
        },
        "54d68b009b634f20965fa50c2d897cce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_175f2ee5c53b48cfaab2a75c94bab140",
            "placeholder": "​",
            "style": "IPY_MODEL_3001fac4ab34434cab70472f947e9879",
            "value": " 36473/36473 [00:09&lt;00:00, 4016.70it/s]"
          }
        },
        "c2d79143086441fd999435085d96f2e9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "077b83ef7d95450fba0d390b41d9f0fa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9ad4a57712664c11b350036a46c7836c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "53daf011f51b4111b0b81b528c1da1a3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "09395ab727904696b073d4ecb434f476": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "175f2ee5c53b48cfaab2a75c94bab140": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3001fac4ab34434cab70472f947e9879": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8345c0000e644364bbfe3f2d8f813e15": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_612ec313a4534a17910621d2a90f5dbf",
              "IPY_MODEL_afbb54a720054840b4875467c9e7e898"
            ],
            "layout": "IPY_MODEL_c040227d3dc4432d8329dab2d127cdc2"
          }
        },
        "612ec313a4534a17910621d2a90f5dbf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e289eed05b92457f9095b9c6dc8f8029",
            "placeholder": "​",
            "style": "IPY_MODEL_9c2835517a28410b860825052927e06d",
            "value": "0.043 MB of 0.043 MB uploaded (0.000 MB deduped)\r"
          }
        },
        "afbb54a720054840b4875467c9e7e898": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b5d380259d684de789e7fa64f1bad8b8",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e5f4b4e5f7a54e7790780d71ccf147cd",
            "value": 1
          }
        },
        "c040227d3dc4432d8329dab2d127cdc2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e289eed05b92457f9095b9c6dc8f8029": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9c2835517a28410b860825052927e06d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b5d380259d684de789e7fa64f1bad8b8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e5f4b4e5f7a54e7790780d71ccf147cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/s3nh/kaggle_toolbox/blob/master/DeBerta_phase.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Tl0rf1lLJTH",
        "outputId": "0e0767b8-9f51-48b1-c0db-c435a4829da5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: wandb in /usr/local/lib/python3.7/dist-packages (0.12.11)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.10.0+cu111)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.17.0)\n",
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.7/dist-packages (0.0)\n",
            "Requirement already satisfied: tokenizers in /usr/local/lib/python3.7/dist-packages (0.11.6)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (0.1.96)\n",
            "Requirement already satisfied: GitPython>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.1.27)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.8.2)\n",
            "Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.3)\n",
            "Requirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.15.0)\n",
            "Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.17.3)\n",
            "Requirement already satisfied: shortuuid>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.0.8)\n",
            "Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.5.8)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.4.8)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: pathtools in /usr/local/lib/python3.7/dist-packages (from wandb) (0.1.2)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.7/dist-packages (from wandb) (1.2.2)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (7.1.2)\n",
            "Requirement already satisfied: yaspin>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.1.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from wandb) (6.0)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.23.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb) (4.0.9)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb) (3.10.0.2)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.7/dist-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb) (5.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2021.10.8)\n",
            "Requirement already satisfied: termcolor<2.0.0,>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from yaspin>=1.0.0->wandb) (1.1.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.49)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.63.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.5)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.4.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.7)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sklearn) (1.0.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.7.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (1.4.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (3.1.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install wandb torch transformers sklearn tokenizers sentencepiece"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ====================================================\n",
        "# Library\n",
        "# ====================================================\n",
        "import os\n",
        "import gc\n",
        "import re\n",
        "import ast\n",
        "import sys\n",
        "import copy\n",
        "import json\n",
        "import time\n",
        "import math\n",
        "import shutil\n",
        "import string\n",
        "import pickle\n",
        "import random\n",
        "import joblib\n",
        "import itertools\n",
        "from pathlib import Path\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import scipy as sp\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "pd.set_option('display.max_rows', 500)\n",
        "pd.set_option('display.max_columns', 500)\n",
        "pd.set_option('display.width', 1000)\n",
        "from tqdm.auto import tqdm\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.model_selection import StratifiedKFold, GroupKFold, KFold\n",
        "\n",
        "import torch\n",
        "print(f\"torch.__version__: {torch.__version__}\")\n",
        "import torch.nn as nn\n",
        "from torch.nn import Parameter\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import Adam, SGD, AdamW\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "#os.system('pip uninstall -y transformers')\n",
        "#os.system('pip uninstall -y tokenizers')\n",
        "#os.system('python -m pip install --no-index --find-links=../input/pppm-pip-wheels transformers')\n",
        "#os.system('python -m pip install --no-index --find-links=../input/pppm-pip-wheels tokenizers')\n",
        "import tokenizers\n",
        "import transformers\n",
        "print(f\"tokenizers.__version__: {tokenizers.__version__}\")\n",
        "print(f\"transformers.__version__: {transformers.__version__}\")\n",
        "from transformers import AutoTokenizer, AutoModel, AutoConfig\n",
        "from transformers import get_linear_schedule_with_warmup, get_cosine_schedule_with_warmup\n",
        "%env TOKENIZERS_PARALLELISM=true\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f1DXsKatoqGV",
        "outputId": "254c6535-4cd0-47af-bbcc-b4b7e79eb797"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.__version__: 1.10.0+cu111\n",
            "tokenizers.__version__: 0.11.6\n",
            "transformers.__version__: 4.17.0\n",
            "env: TOKENIZERS_PARALLELISM=true\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ====================================================\n",
        "# CFG\n",
        "# ====================================================\n",
        "class CFG:\n",
        "    wandb=True\n",
        "    competition='PPPM'\n",
        "    _wandb_kernel='s3nh'\n",
        "    debug=False\n",
        "    apex=True\n",
        "    print_freq=100\n",
        "    num_workers=4\n",
        "    model=\"microsoft/deberta-v3-large\"\n",
        "    scheduler='cosine' # ['linear', 'cosine']\n",
        "    batch_scheduler=True\n",
        "    num_cycles=0.5\n",
        "    num_warmup_steps=12\n",
        "    epochs=4\n",
        "    encoder_lr=5e-6\n",
        "    decoder_lr=5e-6\n",
        "    min_lr=1e-6\n",
        "    eps=1e-7\n",
        "    betas=(0.9, 0.999)\n",
        "    batch_size= 16\n",
        "    fc_dropout=0.05\n",
        "    target_size=1\n",
        "    max_len=164\n",
        "    weight_decay=0.001\n",
        "    gradient_accumulation_steps=1\n",
        "    max_grad_norm=1000\n",
        "    seed=42\n",
        "    n_fold=3\n",
        "    trn_fold=[0, 1, 2]\n",
        "    train=True\n",
        "    \n",
        "if CFG.debug:\n",
        "    CFG.epochs = 2\n",
        "    CFG.trn_fold = [0]"
      ],
      "metadata": {
        "id": "cnAvX5L6LUw0"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ====================================================\n",
        "# wandb\n",
        "# ====================================================\n",
        "if CFG.wandb:\n",
        "    \n",
        "    import wandb\n",
        "\n",
        "    try:\n",
        "        from kaggle_secrets import UserSecretsClient\n",
        "        user_secrets = UserSecretsClient()\n",
        "        secret_value_0 = user_secrets.get_secret(\"wandb_api\")\n",
        "        wandb.login(key=secret_value_0)\n",
        "        anony = None\n",
        "    except:\n",
        "        anony = \"must\"\n",
        "        print('If you want to use your W&B account, go to Add-ons -> Secrets and provide your W&B access token. Use the Label name as wandb_api. \\nGet your W&B access token from here: https://wandb.ai/authorize')\n",
        "\n",
        "\n",
        "    def class2dict(f):\n",
        "        return dict((name, getattr(f, name)) for name in dir(f) if not name.startswith('__'))\n",
        "\n",
        "    run = wandb.init(project='PPPM-Public', \n",
        "                     name=CFG.model,\n",
        "                     config=class2dict(CFG),\n",
        "                     group=CFG.model,\n",
        "                     job_type=\"train\",\n",
        "                     anonymous=anony)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "id": "wsQNy4cROsqj",
        "outputId": "a82b7987-715e-43d2-b323-a11b7d94e686"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "If you want to use your W&B account, go to Add-ons -> Secrets and provide your W&B access token. Use the Label name as wandb_api. \n",
            "Get your W&B access token from here: https://wandb.ai/authorize\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33manony-mouse-222846\u001b[0m (use `wandb login --relogin` to force relogin)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.12.11"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20220324_084002-30ouob32</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/anony-mouse-222846/PPPM-Public/runs/30ouob32?apiKey=5cbad29da28922738e391eea01705005e1fa3ffb\" target=\"_blank\">microsoft/deberta-v3-large</a></strong> to <a href=\"https://wandb.ai/anony-mouse-222846/PPPM-Public?apiKey=5cbad29da28922738e391eea01705005e1fa3ffb\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ====================================================\n",
        "# Library\n",
        "# ====================================================\n",
        "import os\n",
        "import gc\n",
        "import re\n",
        "import ast\n",
        "import sys\n",
        "import copy\n",
        "import json\n",
        "import time\n",
        "import math\n",
        "import shutil\n",
        "import string\n",
        "import pickle\n",
        "import random\n",
        "import joblib\n",
        "import itertools\n",
        "from pathlib import Path\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import scipy as sp\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "pd.set_option('display.max_rows', 500)\n",
        "pd.set_option('display.max_columns', 500)\n",
        "pd.set_option('display.width', 1000)\n",
        "from tqdm.auto import tqdm\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.model_selection import StratifiedKFold, GroupKFold, KFold\n",
        "\n",
        "import torch\n",
        "print(f\"torch.__version__: {torch.__version__}\")\n",
        "import torch.nn as nn\n",
        "from torch.nn import Parameter\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import Adam, SGD, AdamW\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "#os.system('pip uninstall -y transformers')\n",
        "#os.system('pip uninstall -y tokenizers')\n",
        "#os.system('python -m pip install --no-index --find-links=../input/pppm-pip-wheels transformers')\n",
        "#os.system('python -m pip install --no-index --find-links=../input/pppm-pip-wheels tokenizers')\n",
        "import tokenizers\n",
        "import transformers\n",
        "print(f\"tokenizers.__version__: {tokenizers.__version__}\")\n",
        "print(f\"transformers.__version__: {transformers.__version__}\")\n",
        "from transformers import AutoTokenizer, AutoModel, AutoConfig\n",
        "from transformers import get_linear_schedule_with_warmup, get_cosine_schedule_with_warmup\n",
        "%env TOKENIZERS_PARALLELISM=true\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ef4NCunSOt7i",
        "outputId": "6ab94d32-add9-4424-d501-39f49d39480f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.__version__: 1.10.0+cu111\n",
            "tokenizers.__version__: 0.11.6\n",
            "transformers.__version__: 4.17.0\n",
            "env: TOKENIZERS_PARALLELISM=true\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ====================================================\n",
        "# Utils\n",
        "# ====================================================\n",
        "OUTPUT_DIR = './'\n",
        "def get_score(y_true, y_pred):\n",
        "    score = sp.stats.pearsonr(y_true, y_pred)[0]\n",
        "    return score\n",
        "\n",
        "\n",
        "def get_logger(filename=OUTPUT_DIR+'train'):\n",
        "    from logging import getLogger, INFO, StreamHandler, FileHandler, Formatter\n",
        "    logger = getLogger(__name__)\n",
        "    logger.setLevel(INFO)\n",
        "    handler1 = StreamHandler()\n",
        "    handler1.setFormatter(Formatter(\"%(message)s\"))\n",
        "    handler2 = FileHandler(filename=f\"{filename}.log\")\n",
        "    handler2.setFormatter(Formatter(\"%(message)s\"))\n",
        "    logger.addHandler(handler1)\n",
        "    logger.addHandler(handler2)\n",
        "    return logger\n",
        "\n",
        "LOGGER = get_logger()\n",
        "\n",
        "def seed_everything(seed=42):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    \n",
        "seed_everything(seed=42)"
      ],
      "metadata": {
        "id": "Fv_bMOveO1Es"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "INPUT_DIR = 'drive/MyDrive/Colab Notebooks/us-patent-phase/'"
      ],
      "metadata": {
        "id": "EbHhwSibO2jS"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "OUTPUT_DIR = 'drive/MyDrive/Colab Notebooks/us-patent-phase/output/'\n",
        "os.makedirs(OUTPUT_DIR, exist_ok = True)"
      ],
      "metadata": {
        "id": "w20-KIIOmkVm"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = pd.read_csv(INPUT_DIR+'train.csv')\n",
        "test = pd.read_csv(INPUT_DIR+'test.csv')\n",
        "submission = pd.read_csv(INPUT_DIR+'sample_submission.csv')\n",
        "print(f\"train.shape: {train.shape}\")\n",
        "print(f\"test.shape: {test.shape}\")\n",
        "print(f\"submission.shape: {submission.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ig0tDXLjT0cM",
        "outputId": "0b07389c-50d9-4e0d-d97a-bc8421a72ed9"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train.shape: (36473, 5)\n",
            "test.shape: (36, 4)\n",
            "submission.shape: (36, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ====================================================\n",
        "# CPC Data\n",
        "# ====================================================\n",
        "def get_cpc_texts():\n",
        "    contexts = []\n",
        "    pattern = '[A-Z]\\d+'\n",
        "    for file_name in os.listdir(INPUT_DIR + '/CPCSchemeXML202105'):\n",
        "        result = re.findall(pattern, file_name)\n",
        "        if result:\n",
        "            contexts.append(result)\n",
        "    contexts = sorted(set(sum(contexts, [])))\n",
        "    results = {}\n",
        "    for cpc in ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'Y']:\n",
        "        with open(INPUT_DIR + f'CPCTitleList202202/cpc-section-{cpc}_20220201.txt') as f:\n",
        "            s = f.read()\n",
        "        pattern = f'{cpc}\\t\\t.+'\n",
        "        result = re.findall(pattern, s)\n",
        "        cpc_result = result[0].lstrip(pattern)\n",
        "        for context in [c for c in contexts if c[0] == cpc]:\n",
        "            pattern = f'{context}\\t\\t.+'\n",
        "            result = re.findall(pattern, s)\n",
        "            results[context] = cpc_result + \". \" + result[0].lstrip(pattern)\n",
        "    return results\n",
        "\n",
        "\n",
        "cpc_texts = get_cpc_texts()\n",
        "torch.save(cpc_texts, OUTPUT_DIR+\"cpc_texts.pth\")\n",
        "train['context_text'] = train['context'].map(cpc_texts)\n",
        "test['context_text'] = test['context'].map(cpc_texts)\n"
      ],
      "metadata": {
        "id": "nEdeE0nRUNt0"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train['text'] = train['anchor'] + '[SEP]' + train['target'] + '[SEP]'  + train['context_text']\n",
        "test['text'] = test['anchor'] + '[SEP]' + test['target'] + '[SEP]'  + test['context_text']\n"
      ],
      "metadata": {
        "id": "QVpLU7wnUPS7"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ====================================================\n",
        "# CV split\n",
        "# ====================================================\n",
        "train['score_map'] = train['score'].map({0.00: 0, 0.25: 1, 0.50: 2, 0.75: 3, 1.00: 4})\n",
        "Fold = StratifiedKFold(n_splits=CFG.n_fold, shuffle=True, random_state=CFG.seed)\n",
        "for n, (train_index, val_index) in enumerate(Fold.split(train, train['score_map'])):\n",
        "    train.loc[val_index, 'fold'] = int(n)\n",
        "train['fold'] = train['fold'].astype(int)\n",
        "display(train.groupby('fold').size())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "id": "OdcAuS3SnH0m",
        "outputId": "062b4d11-f464-4c3c-f410-503f37261bac"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "fold\n",
              "0    12158\n",
              "1    12158\n",
              "2    12157\n",
              "dtype: int64"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load tokenizer object"
      ],
      "metadata": {
        "id": "wffVb1n5nfMc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(CFG.model)\n",
        "tokenizer.save_pretrained(OUTPUT_DIR + 'tokenizer/')\n",
        "CFG.tokenizer = tokenizer\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MoIO8qiDnUK2",
        "outputId": "58525347-4219-4cd1-a730-f0bcb15b5f53"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ====================================================\n",
        "# Define max_len\n",
        "# ====================================================\n",
        "lengths_dict = {}\n",
        "\n",
        "lengths = []\n",
        "tk0 = tqdm(cpc_texts.values(), total=len(cpc_texts))\n",
        "for text in tk0:\n",
        "    length = len(tokenizer(text, add_special_tokens=False)['input_ids'])\n",
        "    lengths.append(length)\n",
        "lengths_dict['context_text'] = lengths\n",
        "\n",
        "for text_col in ['anchor', 'target']:\n",
        "    lengths = []\n",
        "    tk0 = tqdm(train[text_col].fillna(\"\").values, total=len(train))\n",
        "    for text in tk0:\n",
        "        length = len(tokenizer(text, add_special_tokens=False)['input_ids'])\n",
        "        lengths.append(length)\n",
        "    lengths_dict[text_col] = lengths\n",
        "    \n",
        "CFG.max_len = max(lengths_dict['anchor']) + max(lengths_dict['target'])\\\n",
        "                + max(lengths_dict['context_text']) + 4 # CLS + SEP + SEP + SEP\n",
        "LOGGER.info(f\"max_len: {CFG.max_len}\")"
      ],
      "metadata": {
        "id": "2M46-5K1nu4M",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131,
          "referenced_widgets": [
            "d8db1f91cda04c9d8b98cfe01aa51739",
            "45f25b300db64d8e9929e0c622634f05",
            "6576f9812d5a4874b3841ba16841006a",
            "481106f273be4f4ba3ddec2ccaee99c2",
            "f3446fad150744a3ac93c699db10d3c9",
            "71b68985043741d88b3e9697d641f8c2",
            "4f82b1f5f05f4d0db94459b56ccbe2bf",
            "446ffbbb92ec4332bdb556f761350c2e",
            "f4ce147f6a7046d2a2d5eb7017963d00",
            "45147e40eae84068847dc721e0615700",
            "8a163542584541bc87fcc24962845078",
            "e881d10db4564725bea065433ac8bf19",
            "c2c664a5ec4d45928438da5b5c0ae6d9",
            "8133e18115a34b3e8580a73ab4e58d0a",
            "cf54968193024fd6b382a18381700a05",
            "d294d55ed23c45fdb17c0fa7869e04aa",
            "cf0ca9e7e4e64c7a8d0ed949e6f0fc09",
            "44a9f8c696d44f3ea73744e8b8b7f2a4",
            "84174fe4dbeb4b519f5d166c75c86eef",
            "b1022f656b124b349a8c83b462d72170",
            "bc768533ff9448119b9eb65154b1b2b1",
            "daff355e2b8749059346592ec7e17c10",
            "34293e2f302f4592802e0c572115a40d",
            "3f57a1626a4f4a8b97e4b55a663fcd67",
            "ea0baf8532dd4115bbd7007d1ee8484c",
            "54d68b009b634f20965fa50c2d897cce",
            "c2d79143086441fd999435085d96f2e9",
            "077b83ef7d95450fba0d390b41d9f0fa",
            "9ad4a57712664c11b350036a46c7836c",
            "53daf011f51b4111b0b81b528c1da1a3",
            "09395ab727904696b073d4ecb434f476",
            "175f2ee5c53b48cfaab2a75c94bab140",
            "3001fac4ab34434cab70472f947e9879"
          ]
        },
        "outputId": "75874354-9848-45da-bd9a-5561bb025d65"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/136 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d8db1f91cda04c9d8b98cfe01aa51739"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/36473 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e881d10db4564725bea065433ac8bf19"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/36473 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "34293e2f302f4592802e0c572115a40d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "max_len: 133\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ====================================================\n",
        "# Dataset\n",
        "# ====================================================\n",
        "def prepare_input(cfg, text):\n",
        "    inputs = cfg.tokenizer(text,\n",
        "                           add_special_tokens=True,\n",
        "                           max_length=cfg.max_len,\n",
        "                           padding=\"max_length\",\n",
        "                           return_offsets_mapping=False)\n",
        "    for k, v in inputs.items():\n",
        "        inputs[k] = torch.tensor(v, dtype=torch.long)\n",
        "    return inputs\n",
        "\n",
        "\n",
        "class TrainDataset(Dataset):\n",
        "    def __init__(self, cfg, df):\n",
        "        self.cfg = cfg\n",
        "        self.texts = df['text'].values\n",
        "        self.labels = df['score'].values\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, item):\n",
        "        inputs = prepare_input(self.cfg, self.texts[item])\n",
        "        label = torch.tensor(self.labels[item], dtype=torch.float)\n",
        "        return inputs, label"
      ],
      "metadata": {
        "id": "LXY7SXPvqX5R"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ====================================================\n",
        "# Model\n",
        "# ====================================================\n",
        "class CustomModel(nn.Module):\n",
        "    def __init__(self, cfg, config_path=None, pretrained=False):\n",
        "        super().__init__()\n",
        "        self.cfg = cfg\n",
        "        if config_path is None:\n",
        "            self.config = AutoConfig.from_pretrained(cfg.model, output_hidden_states=True)\n",
        "        else:\n",
        "            self.config = torch.load(config_path)\n",
        "        if pretrained:\n",
        "            self.model = AutoModel.from_pretrained(cfg.model, config=self.config)\n",
        "        else:\n",
        "            self.model = AutoModel.from_config(self.config)\n",
        "        self.fc_dropout = nn.Dropout(cfg.fc_dropout)\n",
        "        self.fc = nn.Linear(self.config.hidden_size, self.cfg.target_size)\n",
        "        self._init_weights(self.fc)\n",
        "        self.attention = nn.Sequential(\n",
        "            nn.Linear(self.config.hidden_size, 512),\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(512, 1),\n",
        "            nn.Softmax(dim=1)\n",
        "        )\n",
        "        self._init_weights(self.attention)\n",
        "        \n",
        "    def _init_weights(self, module):\n",
        "        if isinstance(module, nn.Linear):\n",
        "            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n",
        "            if module.bias is not None:\n",
        "                module.bias.data.zero_()\n",
        "        elif isinstance(module, nn.Embedding):\n",
        "            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n",
        "            if module.padding_idx is not None:\n",
        "                module.weight.data[module.padding_idx].zero_()\n",
        "        elif isinstance(module, nn.LayerNorm):\n",
        "            module.bias.data.zero_()\n",
        "            module.weight.data.fill_(1.0)\n",
        "        \n",
        "    def feature(self, inputs):\n",
        "        outputs = self.model(**inputs)\n",
        "        last_hidden_states = outputs[0]\n",
        "        # feature = torch.mean(last_hidden_states, 1)\n",
        "        weights = self.attention(last_hidden_states)\n",
        "        feature = torch.sum(weights * last_hidden_states, dim=1)\n",
        "        return feature\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        feature = self.feature(inputs)\n",
        "        output = self.fc(self.fc_dropout(feature))\n",
        "        return output"
      ],
      "metadata": {
        "id": "Qtj9OsOeqs3b"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ====================================================\n",
        "# Helper functions\n",
        "# ====================================================\n",
        "class AverageMeter(object):\n",
        "    \"\"\"Computes and stores the average and current value\"\"\"\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "\n",
        "    def update(self, val, n=1):\n",
        "        self.val = val\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count\n",
        "\n",
        "\n",
        "def asMinutes(s):\n",
        "    m = math.floor(s / 60)\n",
        "    s -= m * 60\n",
        "    return '%dm %ds' % (m, s)\n",
        "\n",
        "\n",
        "def timeSince(since, percent):\n",
        "    now = time.time()\n",
        "    s = now - since\n",
        "    es = s / (percent)\n",
        "    rs = es - s\n",
        "    return '%s (remain %s)' % (asMinutes(s), asMinutes(rs))\n",
        "\n",
        "\n",
        "def train_fn(fold, train_loader, model, criterion, optimizer, epoch, scheduler, device):\n",
        "    model.train()\n",
        "    scaler = torch.cuda.amp.GradScaler(enabled=CFG.apex)\n",
        "    losses = AverageMeter()\n",
        "    start = end = time.time()\n",
        "    global_step = 0\n",
        "    for step, (inputs, labels) in enumerate(train_loader):\n",
        "        for k, v in inputs.items():\n",
        "            inputs[k] = v.to(device)\n",
        "        labels = labels.to(device)\n",
        "        batch_size = labels.size(0)\n",
        "        with torch.cuda.amp.autocast(enabled=CFG.apex):\n",
        "            y_preds = model(inputs)\n",
        "        loss = criterion(y_preds.view(-1, 1), labels.view(-1, 1))\n",
        "        if CFG.gradient_accumulation_steps > 1:\n",
        "            loss = loss / CFG.gradient_accumulation_steps\n",
        "        losses.update(loss.item(), batch_size)\n",
        "        scaler.scale(loss).backward()\n",
        "        grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), CFG.max_grad_norm)\n",
        "        if (step + 1) % CFG.gradient_accumulation_steps == 0:\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "            optimizer.zero_grad()\n",
        "            global_step += 1\n",
        "            if CFG.batch_scheduler:\n",
        "                scheduler.step()\n",
        "        end = time.time()\n",
        "        if step % CFG.print_freq == 0 or step == (len(train_loader)-1):\n",
        "            print('Epoch: [{0}][{1}/{2}] '\n",
        "                  'Elapsed {remain:s} '\n",
        "                  'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n",
        "                  'Grad: {grad_norm:.4f}  '\n",
        "                  'LR: {lr:.8f}  '\n",
        "                  .format(epoch+1, step, len(train_loader), \n",
        "                          remain=timeSince(start, float(step+1)/len(train_loader)),\n",
        "                          loss=losses,\n",
        "                          grad_norm=grad_norm,\n",
        "                          lr=scheduler.get_lr()[0]))\n",
        "        if CFG.wandb:\n",
        "            wandb.log({f\"[fold{fold}] loss\": losses.val,\n",
        "                       f\"[fold{fold}] lr\": scheduler.get_lr()[0]})\n",
        "    return losses.avg\n",
        "\n",
        "\n",
        "def valid_fn(valid_loader, model, criterion, device):\n",
        "    losses = AverageMeter()\n",
        "    model.eval()\n",
        "    preds = []\n",
        "    start = end = time.time()\n",
        "    for step, (inputs, labels) in enumerate(valid_loader):\n",
        "        for k, v in inputs.items():\n",
        "            inputs[k] = v.to(device)\n",
        "        labels = labels.to(device)\n",
        "        batch_size = labels.size(0)\n",
        "        with torch.no_grad():\n",
        "            y_preds = model(inputs)\n",
        "        loss = criterion(y_preds.view(-1, 1), labels.view(-1, 1))\n",
        "        if CFG.gradient_accumulation_steps > 1:\n",
        "            loss = loss / CFG.gradient_accumulation_steps\n",
        "        losses.update(loss.item(), batch_size)\n",
        "        preds.append(y_preds.sigmoid().to('cpu').numpy())\n",
        "        end = time.time()\n",
        "        if step % CFG.print_freq == 0 or step == (len(valid_loader)-1):\n",
        "            print('EVAL: [{0}/{1}] '\n",
        "                  'Elapsed {remain:s} '\n",
        "                  'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n",
        "                  .format(step, len(valid_loader),\n",
        "                          loss=losses,\n",
        "                          remain=timeSince(start, float(step+1)/len(valid_loader))))\n",
        "    predictions = np.concatenate(preds)\n",
        "    predictions = np.concatenate(predictions)\n",
        "    return losses.avg, predictions\n",
        "\n",
        "\n",
        "def inference_fn(test_loader, model, device):\n",
        "    preds = []\n",
        "    model.eval()\n",
        "    model.to(device)\n",
        "    tk0 = tqdm(test_loader, total=len(test_loader))\n",
        "    for inputs in tk0:\n",
        "        for k, v in inputs.items():\n",
        "            inputs[k] = v.to(device)\n",
        "        with torch.no_grad():\n",
        "            y_preds = model(inputs)\n",
        "        preds.append(y_preds.sigmoid().to('cpu').numpy())\n",
        "    predictions = np.concatenate(preds)\n",
        "    return predictions"
      ],
      "metadata": {
        "id": "6F2ZBGAtqufp"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ====================================================\n",
        "# train loop\n",
        "# ====================================================\n",
        "def train_loop(folds, fold):\n",
        "    \n",
        "    LOGGER.info(f\"========== fold: {fold} training ==========\")\n",
        "\n",
        "    # ====================================================\n",
        "    # loader\n",
        "    # ====================================================\n",
        "    train_folds = folds[folds['fold'] != fold].reset_index(drop=True)\n",
        "    valid_folds = folds[folds['fold'] == fold].reset_index(drop=True)\n",
        "    valid_labels = valid_folds['score'].values\n",
        "    \n",
        "    train_dataset = TrainDataset(CFG, train_folds)\n",
        "    valid_dataset = TrainDataset(CFG, valid_folds)\n",
        "\n",
        "    train_loader = DataLoader(train_dataset,\n",
        "                              batch_size=CFG.batch_size,\n",
        "                              shuffle=True,\n",
        "                              num_workers=CFG.num_workers, pin_memory=True, drop_last=True)\n",
        "    valid_loader = DataLoader(valid_dataset,\n",
        "                              batch_size=CFG.batch_size,\n",
        "                              shuffle=False,\n",
        "                              num_workers=CFG.num_workers, pin_memory=True, drop_last=False)\n",
        "\n",
        "    # ====================================================\n",
        "    # model & optimizer\n",
        "    # ====================================================\n",
        "    model = CustomModel(CFG, config_path=None, pretrained=True)\n",
        "    torch.save(model.config, OUTPUT_DIR+'config.pth')\n",
        "    model.to(device)\n",
        "    \n",
        "    def get_optimizer_params(model, encoder_lr, decoder_lr, weight_decay=0.0):\n",
        "        param_optimizer = list(model.named_parameters())\n",
        "        no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n",
        "        optimizer_parameters = [\n",
        "            {'params': [p for n, p in model.model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
        "             'lr': encoder_lr, 'weight_decay': weight_decay},\n",
        "            {'params': [p for n, p in model.model.named_parameters() if any(nd in n for nd in no_decay)],\n",
        "             'lr': encoder_lr, 'weight_decay': 0.0},\n",
        "            {'params': [p for n, p in model.named_parameters() if \"model\" not in n],\n",
        "             'lr': decoder_lr, 'weight_decay': 0.0}\n",
        "        ]\n",
        "        return optimizer_parameters\n",
        "\n",
        "    optimizer_parameters = get_optimizer_params(model,\n",
        "                                                encoder_lr=CFG.encoder_lr, \n",
        "                                                decoder_lr=CFG.decoder_lr,\n",
        "                                                weight_decay=CFG.weight_decay)\n",
        "    optimizer = AdamW(optimizer_parameters, lr=CFG.encoder_lr, eps=CFG.eps, betas=CFG.betas)\n",
        "    \n",
        "    # ====================================================\n",
        "    # scheduler\n",
        "    # ====================================================\n",
        "    def get_scheduler(cfg, optimizer, num_train_steps):\n",
        "        if cfg.scheduler == 'linear':\n",
        "            scheduler = get_linear_schedule_with_warmup(\n",
        "                optimizer, num_warmup_steps=cfg.num_warmup_steps, num_training_steps=num_train_steps\n",
        "            )\n",
        "        elif cfg.scheduler == 'cosine':\n",
        "            scheduler = get_cosine_schedule_with_warmup(\n",
        "                optimizer, num_warmup_steps=cfg.num_warmup_steps, num_training_steps=num_train_steps, num_cycles=cfg.num_cycles\n",
        "            )\n",
        "        return scheduler\n",
        "    \n",
        "    num_train_steps = int(len(train_folds) / CFG.batch_size * CFG.epochs)\n",
        "    scheduler = get_scheduler(CFG, optimizer, num_train_steps)\n",
        "\n",
        "    # ====================================================\n",
        "    # loop\n",
        "    # ====================================================\n",
        "    criterion = nn.BCEWithLogitsLoss(reduction=\"mean\")\n",
        "    \n",
        "    best_score = 0.\n",
        "\n",
        "    for epoch in range(CFG.epochs):\n",
        "\n",
        "        start_time = time.time()\n",
        "\n",
        "        # train\n",
        "        avg_loss = train_fn(fold, train_loader, model, criterion, optimizer, epoch, scheduler, device)\n",
        "\n",
        "        # eval\n",
        "        avg_val_loss, predictions = valid_fn(valid_loader, model, criterion, device)\n",
        "        \n",
        "        # scoring\n",
        "        score = get_score(valid_labels, predictions)\n",
        "\n",
        "        elapsed = time.time() - start_time\n",
        "\n",
        "        LOGGER.info(f'Epoch {epoch+1} - avg_train_loss: {avg_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  time: {elapsed:.0f}s')\n",
        "        LOGGER.info(f'Epoch {epoch+1} - Score: {score:.4f}')\n",
        "        if CFG.wandb:\n",
        "            wandb.log({f\"[fold{fold}] epoch\": epoch+1, \n",
        "                       f\"[fold{fold}] avg_train_loss\": avg_loss, \n",
        "                       f\"[fold{fold}] avg_val_loss\": avg_val_loss,\n",
        "                       f\"[fold{fold}] score\": score})\n",
        "        \n",
        "        if best_score < score:\n",
        "            best_score = score\n",
        "            LOGGER.info(f'Epoch {epoch+1} - Save Best Score: {best_score:.4f} Model')\n",
        "            torch.save({'model': model.state_dict(),\n",
        "                        'predictions': predictions},\n",
        "                        OUTPUT_DIR+f\"{CFG.model.replace('/', '-')}_fold{fold}_best_2folds_{CFG.epochs}_{CFG.batch_size}_{CFG.max_len}_{CFG.n_fold}.pth\")\n",
        "\n",
        "    predictions = torch.load(OUTPUT_DIR+f\"{CFG.model.replace('/', '-')}_fold{fold}_best_2folds_{CFG.epochs}_{CFG.batch_size}_{CFG.max_len}_{CFG.n_fold}.pth\", \n",
        "                             map_location=torch.device('cpu'))['predictions']\n",
        "    valid_folds['pred'] = predictions\n",
        "\n",
        "    torch.cuda.empty_cache()\n",
        "    gc.collect()\n",
        "    \n",
        "    return valid_folds"
      ],
      "metadata": {
        "id": "T9sC7JL8qzuu"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "    \n",
        "    def get_result(oof_df):\n",
        "        labels = oof_df['score'].values\n",
        "        preds = oof_df['pred'].values\n",
        "        score = get_score(labels, preds)\n",
        "        LOGGER.info(f'Score: {score:<.4f}')\n",
        "    \n",
        "    if CFG.train:\n",
        "        oof_df = pd.DataFrame()\n",
        "        for fold in range(CFG.n_fold):\n",
        "            if fold in CFG.trn_fold:\n",
        "                _oof_df = train_loop(train, fold)\n",
        "                oof_df = pd.concat([oof_df, _oof_df])\n",
        "                LOGGER.info(f\"========== fold: {fold} result ==========\")\n",
        "                get_result(_oof_df)\n",
        "        oof_df = oof_df.reset_index(drop=True)\n",
        "        LOGGER.info(f\"========== CV ==========\")\n",
        "        get_result(oof_df)\n",
        "        oof_df.to_pickle(OUTPUT_DIR+'oof_df.pkl')\n",
        "        \n",
        "    if CFG.wandb:\n",
        "        wandb.finish()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "8345c0000e644364bbfe3f2d8f813e15",
            "612ec313a4534a17910621d2a90f5dbf",
            "afbb54a720054840b4875467c9e7e898",
            "c040227d3dc4432d8329dab2d127cdc2",
            "e289eed05b92457f9095b9c6dc8f8029",
            "9c2835517a28410b860825052927e06d",
            "b5d380259d684de789e7fa64f1bad8b8",
            "e5f4b4e5f7a54e7790780d71ccf147cd"
          ]
        },
        "id": "zK14vUP6q3tw",
        "outputId": "6f53007d-fd0b-4a09-89d7-17044a451e14"
      },
      "execution_count": 19,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "========== fold: 0 training ==========\n",
            "Some weights of the model checkpoint at microsoft/deberta-v3-large were not used when initializing DebertaV2Model: ['mask_predictions.dense.bias', 'mask_predictions.classifier.weight', 'mask_predictions.LayerNorm.weight', 'mask_predictions.LayerNorm.bias', 'lm_predictions.lm_head.bias', 'mask_predictions.classifier.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.dense.weight', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.LayerNorm.bias']\n",
            "- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: [1][0/1519] Elapsed 0m 1s (remain 31m 10s) Loss: 0.6775(0.6775) Grad: inf  LR: 0.00000042  \n",
            "Epoch: [1][100/1519] Elapsed 1m 39s (remain 23m 17s) Loss: 0.6360(0.6537) Grad: 92915.4062  LR: 0.00000500  \n",
            "Epoch: [1][200/1519] Elapsed 3m 17s (remain 21m 34s) Loss: 0.5811(0.6272) Grad: 106748.0859  LR: 0.00000499  \n",
            "Epoch: [1][300/1519] Elapsed 4m 55s (remain 19m 54s) Loss: 0.5971(0.6159) Grad: 52412.8164  LR: 0.00000497  \n",
            "Epoch: [1][400/1519] Elapsed 6m 33s (remain 18m 15s) Loss: 0.6686(0.6047) Grad: 120168.7266  LR: 0.00000495  \n",
            "Epoch: [1][500/1519] Elapsed 8m 11s (remain 16m 37s) Loss: 0.5912(0.5982) Grad: 64891.4102  LR: 0.00000492  \n",
            "Epoch: [1][600/1519] Elapsed 9m 48s (remain 14m 59s) Loss: 0.6013(0.5922) Grad: 125086.5938  LR: 0.00000488  \n",
            "Epoch: [1][700/1519] Elapsed 11m 26s (remain 13m 21s) Loss: 0.4870(0.5877) Grad: 70837.1328  LR: 0.00000484  \n",
            "Epoch: [1][800/1519] Elapsed 13m 4s (remain 11m 43s) Loss: 0.5604(0.5839) Grad: 91110.9062  LR: 0.00000479  \n",
            "Epoch: [1][900/1519] Elapsed 14m 42s (remain 10m 5s) Loss: 0.6726(0.5785) Grad: 66346.7969  LR: 0.00000474  \n",
            "Epoch: [1][1000/1519] Elapsed 16m 20s (remain 8m 27s) Loss: 0.5506(0.5761) Grad: 115949.6562  LR: 0.00000468  \n",
            "Epoch: [1][1100/1519] Elapsed 17m 58s (remain 6m 49s) Loss: 0.5977(0.5738) Grad: 204270.2188  LR: 0.00000461  \n",
            "Epoch: [1][1200/1519] Elapsed 19m 36s (remain 5m 11s) Loss: 0.5851(0.5724) Grad: 69699.3594  LR: 0.00000454  \n",
            "Epoch: [1][1300/1519] Elapsed 21m 14s (remain 3m 33s) Loss: 0.6139(0.5713) Grad: 141106.6406  LR: 0.00000446  \n",
            "Epoch: [1][1400/1519] Elapsed 22m 52s (remain 1m 55s) Loss: 0.4692(0.5693) Grad: 67851.3359  LR: 0.00000438  \n",
            "Epoch: [1][1500/1519] Elapsed 24m 30s (remain 0m 17s) Loss: 0.4803(0.5678) Grad: 22402.9414  LR: 0.00000429  \n",
            "Epoch: [1][1518/1519] Elapsed 24m 47s (remain 0m 0s) Loss: 0.5579(0.5673) Grad: 36289.5938  LR: 0.00000428  \n",
            "EVAL: [0/760] Elapsed 0m 0s (remain 7m 17s) Loss: 0.4462(0.4462) \n",
            "EVAL: [100/760] Elapsed 0m 31s (remain 3m 27s) Loss: 0.6294(0.5502) \n",
            "EVAL: [200/760] Elapsed 1m 2s (remain 2m 54s) Loss: 0.4939(0.5429) \n",
            "EVAL: [300/760] Elapsed 1m 33s (remain 2m 23s) Loss: 0.4719(0.5453) \n",
            "EVAL: [400/760] Elapsed 2m 5s (remain 1m 51s) Loss: 0.6135(0.5455) \n",
            "EVAL: [500/760] Elapsed 2m 36s (remain 1m 20s) Loss: 0.3707(0.5471) \n",
            "EVAL: [600/760] Elapsed 3m 7s (remain 0m 49s) Loss: 0.5851(0.5462) \n",
            "EVAL: [700/760] Elapsed 3m 38s (remain 0m 18s) Loss: 0.4934(0.5453) \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1 - avg_train_loss: 0.5673  avg_val_loss: 0.5443  time: 1725s\n",
            "Epoch 1 - Score: 0.8358\n",
            "Epoch 1 - Save Best Score: 0.8358 Model\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EVAL: [759/760] Elapsed 3m 56s (remain 0m 0s) Loss: 0.4953(0.5443) \n",
            "Epoch: [2][0/1519] Elapsed 0m 1s (remain 31m 28s) Loss: 0.5135(0.5135) Grad: 50110.7695  LR: 0.00000428  \n",
            "Epoch: [2][100/1519] Elapsed 1m 39s (remain 23m 13s) Loss: 0.4983(0.5316) Grad: 88455.0703  LR: 0.00000418  \n",
            "Epoch: [2][200/1519] Elapsed 3m 17s (remain 21m 34s) Loss: 0.4747(0.5339) Grad: 257651.0000  LR: 0.00000408  \n",
            "Epoch: [2][300/1519] Elapsed 4m 55s (remain 19m 54s) Loss: 0.4524(0.5375) Grad: 138076.6250  LR: 0.00000398  \n",
            "Epoch: [2][400/1519] Elapsed 6m 32s (remain 18m 15s) Loss: 0.6052(0.5348) Grad: 235252.3906  LR: 0.00000388  \n",
            "Epoch: [2][500/1519] Elapsed 8m 10s (remain 16m 37s) Loss: 0.5698(0.5325) Grad: 216299.5000  LR: 0.00000377  \n",
            "Epoch: [2][600/1519] Elapsed 9m 48s (remain 14m 59s) Loss: 0.5081(0.5301) Grad: 315224.8750  LR: 0.00000365  \n",
            "Epoch: [2][700/1519] Elapsed 11m 26s (remain 13m 20s) Loss: 0.5205(0.5293) Grad: 56263.7305  LR: 0.00000354  \n",
            "Epoch: [2][800/1519] Elapsed 13m 4s (remain 11m 42s) Loss: 0.5519(0.5299) Grad: 56520.3281  LR: 0.00000342  \n",
            "Epoch: [2][900/1519] Elapsed 14m 42s (remain 10m 5s) Loss: 0.5990(0.5284) Grad: 71909.0781  LR: 0.00000330  \n",
            "Epoch: [2][1000/1519] Elapsed 16m 19s (remain 8m 27s) Loss: 0.4835(0.5279) Grad: 59360.3242  LR: 0.00000317  \n",
            "Epoch: [2][1100/1519] Elapsed 17m 57s (remain 6m 49s) Loss: 0.5106(0.5288) Grad: 33085.9297  LR: 0.00000305  \n",
            "Epoch: [2][1200/1519] Elapsed 19m 35s (remain 5m 11s) Loss: 0.4609(0.5292) Grad: 61010.1055  LR: 0.00000292  \n",
            "Epoch: [2][1300/1519] Elapsed 21m 13s (remain 3m 33s) Loss: 0.4518(0.5296) Grad: 87448.3438  LR: 0.00000279  \n",
            "Epoch: [2][1400/1519] Elapsed 22m 51s (remain 1m 55s) Loss: 0.6149(0.5295) Grad: 64444.4492  LR: 0.00000266  \n",
            "Epoch: [2][1500/1519] Elapsed 24m 29s (remain 0m 17s) Loss: 0.4271(0.5293) Grad: 50593.5547  LR: 0.00000253  \n",
            "Epoch: [2][1518/1519] Elapsed 24m 46s (remain 0m 0s) Loss: 0.5338(0.5295) Grad: 101960.6094  LR: 0.00000251  \n",
            "EVAL: [0/760] Elapsed 0m 0s (remain 6m 55s) Loss: 0.4535(0.4535) \n",
            "EVAL: [100/760] Elapsed 0m 31s (remain 3m 26s) Loss: 0.6317(0.5409) \n",
            "EVAL: [200/760] Elapsed 1m 2s (remain 2m 54s) Loss: 0.4947(0.5343) \n",
            "EVAL: [300/760] Elapsed 1m 33s (remain 2m 23s) Loss: 0.4932(0.5372) \n",
            "EVAL: [400/760] Elapsed 2m 5s (remain 1m 51s) Loss: 0.6126(0.5384) \n",
            "EVAL: [500/760] Elapsed 2m 36s (remain 1m 20s) Loss: 0.3577(0.5402) \n",
            "EVAL: [600/760] Elapsed 3m 7s (remain 0m 49s) Loss: 0.5767(0.5396) \n",
            "EVAL: [700/760] Elapsed 3m 38s (remain 0m 18s) Loss: 0.4919(0.5393) \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2 - avg_train_loss: 0.5295  avg_val_loss: 0.5384  time: 1724s\n",
            "Epoch 2 - Score: 0.8521\n",
            "Epoch 2 - Save Best Score: 0.8521 Model\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EVAL: [759/760] Elapsed 3m 56s (remain 0m 0s) Loss: 0.4763(0.5384) \n",
            "Epoch: [3][0/1519] Elapsed 0m 1s (remain 32m 29s) Loss: 0.5098(0.5098) Grad: 131277.2656  LR: 0.00000251  \n",
            "Epoch: [3][100/1519] Elapsed 1m 39s (remain 23m 13s) Loss: 0.5607(0.5205) Grad: 259519.5938  LR: 0.00000238  \n",
            "Epoch: [3][200/1519] Elapsed 3m 17s (remain 21m 32s) Loss: 0.6034(0.5186) Grad: 347849.9688  LR: 0.00000225  \n",
            "Epoch: [3][300/1519] Elapsed 4m 54s (remain 19m 53s) Loss: 0.5604(0.5205) Grad: 358558.3750  LR: 0.00000212  \n",
            "Epoch: [3][400/1519] Elapsed 6m 32s (remain 18m 14s) Loss: 0.5193(0.5184) Grad: 59494.4609  LR: 0.00000199  \n",
            "Epoch: [3][500/1519] Elapsed 8m 10s (remain 16m 36s) Loss: 0.5240(0.5182) Grad: 135081.3125  LR: 0.00000187  \n",
            "Epoch: [3][600/1519] Elapsed 9m 48s (remain 14m 58s) Loss: 0.3564(0.5176) Grad: 101203.2031  LR: 0.00000174  \n",
            "Epoch: [3][700/1519] Elapsed 11m 25s (remain 13m 20s) Loss: 0.4669(0.5145) Grad: 72108.4141  LR: 0.00000162  \n",
            "Epoch: [3][800/1519] Elapsed 13m 3s (remain 11m 42s) Loss: 0.5328(0.5157) Grad: 55417.8711  LR: 0.00000150  \n",
            "Epoch: [3][900/1519] Elapsed 14m 41s (remain 10m 4s) Loss: 0.4805(0.5153) Grad: 65117.8398  LR: 0.00000138  \n",
            "Epoch: [3][1000/1519] Elapsed 16m 19s (remain 8m 26s) Loss: 0.2592(0.5152) Grad: 91818.2969  LR: 0.00000127  \n",
            "Epoch: [3][1100/1519] Elapsed 17m 57s (remain 6m 48s) Loss: 0.4223(0.5158) Grad: 49124.2305  LR: 0.00000116  \n",
            "Epoch: [3][1200/1519] Elapsed 19m 34s (remain 5m 11s) Loss: 0.4887(0.5162) Grad: 101908.7500  LR: 0.00000105  \n",
            "Epoch: [3][1300/1519] Elapsed 21m 12s (remain 3m 33s) Loss: 0.5925(0.5156) Grad: 37664.7812  LR: 0.00000095  \n",
            "Epoch: [3][1400/1519] Elapsed 22m 50s (remain 1m 55s) Loss: 0.5195(0.5156) Grad: 185444.1562  LR: 0.00000085  \n",
            "Epoch: [3][1500/1519] Elapsed 24m 28s (remain 0m 17s) Loss: 0.5094(0.5158) Grad: 42614.1914  LR: 0.00000075  \n",
            "Epoch: [3][1518/1519] Elapsed 24m 45s (remain 0m 0s) Loss: 0.5518(0.5154) Grad: 42311.4805  LR: 0.00000074  \n",
            "EVAL: [0/760] Elapsed 0m 0s (remain 7m 28s) Loss: 0.4466(0.4466) \n",
            "EVAL: [100/760] Elapsed 0m 31s (remain 3m 27s) Loss: 0.6302(0.5418) \n",
            "EVAL: [200/760] Elapsed 1m 2s (remain 2m 54s) Loss: 0.4917(0.5340) \n",
            "EVAL: [300/760] Elapsed 1m 33s (remain 2m 23s) Loss: 0.4756(0.5367) \n",
            "EVAL: [400/760] Elapsed 2m 5s (remain 1m 51s) Loss: 0.6421(0.5371) \n",
            "EVAL: [500/760] Elapsed 2m 36s (remain 1m 20s) Loss: 0.3586(0.5382) \n",
            "EVAL: [600/760] Elapsed 3m 7s (remain 0m 49s) Loss: 0.5755(0.5378) \n",
            "EVAL: [700/760] Elapsed 3m 38s (remain 0m 18s) Loss: 0.5010(0.5379) \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3 - avg_train_loss: 0.5154  avg_val_loss: 0.5368  time: 1723s\n",
            "Epoch 3 - Score: 0.8550\n",
            "Epoch 3 - Save Best Score: 0.8550 Model\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EVAL: [759/760] Elapsed 3m 56s (remain 0m 0s) Loss: 0.4764(0.5368) \n",
            "Epoch: [4][0/1519] Elapsed 0m 1s (remain 32m 9s) Loss: 0.5975(0.5975) Grad: 169139.7969  LR: 0.00000074  \n",
            "Epoch: [4][100/1519] Elapsed 1m 39s (remain 23m 12s) Loss: 0.4404(0.5009) Grad: 74239.9297  LR: 0.00000065  \n",
            "Epoch: [4][200/1519] Elapsed 3m 16s (remain 21m 31s) Loss: 0.4787(0.5082) Grad: 215283.0938  LR: 0.00000056  \n",
            "Epoch: [4][300/1519] Elapsed 4m 54s (remain 19m 52s) Loss: 0.5551(0.5091) Grad: 111764.5625  LR: 0.00000048  \n",
            "Epoch: [4][400/1519] Elapsed 6m 32s (remain 18m 14s) Loss: 0.6023(0.5083) Grad: 112733.8047  LR: 0.00000041  \n",
            "Epoch: [4][500/1519] Elapsed 8m 10s (remain 16m 36s) Loss: 0.4873(0.5081) Grad: 92161.2031  LR: 0.00000034  \n",
            "Epoch: [4][600/1519] Elapsed 9m 48s (remain 14m 59s) Loss: 0.3396(0.5089) Grad: 111129.2734  LR: 0.00000028  \n",
            "Epoch: [4][700/1519] Elapsed 11m 26s (remain 13m 21s) Loss: 0.5349(0.5107) Grad: 87942.3984  LR: 0.00000022  \n",
            "Epoch: [4][800/1519] Elapsed 13m 4s (remain 11m 42s) Loss: 0.6143(0.5105) Grad: 531433.6875  LR: 0.00000017  \n",
            "Epoch: [4][900/1519] Elapsed 14m 42s (remain 10m 4s) Loss: 0.5276(0.5102) Grad: 54333.3008  LR: 0.00000013  \n",
            "Epoch: [4][1000/1519] Elapsed 16m 19s (remain 8m 27s) Loss: 0.3136(0.5090) Grad: 98309.4062  LR: 0.00000009  \n",
            "Epoch: [4][1100/1519] Elapsed 17m 57s (remain 6m 49s) Loss: 0.5118(0.5088) Grad: 79313.7812  LR: 0.00000006  \n",
            "Epoch: [4][1200/1519] Elapsed 19m 35s (remain 5m 11s) Loss: 0.4687(0.5089) Grad: 61938.7852  LR: 0.00000003  \n",
            "Epoch: [4][1300/1519] Elapsed 21m 13s (remain 3m 33s) Loss: 0.5503(0.5094) Grad: 41492.7383  LR: 0.00000002  \n",
            "Epoch: [4][1400/1519] Elapsed 22m 51s (remain 1m 55s) Loss: 0.4923(0.5096) Grad: 61760.3398  LR: 0.00000000  \n",
            "Epoch: [4][1500/1519] Elapsed 24m 28s (remain 0m 17s) Loss: 0.4715(0.5097) Grad: 140741.8281  LR: 0.00000000  \n",
            "Epoch: [4][1518/1519] Elapsed 24m 46s (remain 0m 0s) Loss: 0.5083(0.5098) Grad: 55569.6641  LR: 0.00000000  \n",
            "EVAL: [0/760] Elapsed 0m 0s (remain 6m 57s) Loss: 0.4405(0.4405) \n",
            "EVAL: [100/760] Elapsed 0m 31s (remain 3m 27s) Loss: 0.6304(0.5476) \n",
            "EVAL: [200/760] Elapsed 1m 2s (remain 2m 55s) Loss: 0.4887(0.5384) \n",
            "EVAL: [300/760] Elapsed 1m 34s (remain 2m 23s) Loss: 0.4829(0.5404) \n",
            "EVAL: [400/760] Elapsed 2m 5s (remain 1m 52s) Loss: 0.6510(0.5412) \n",
            "EVAL: [500/760] Elapsed 2m 36s (remain 1m 20s) Loss: 0.3546(0.5425) \n",
            "EVAL: [600/760] Elapsed 3m 7s (remain 0m 49s) Loss: 0.5745(0.5418) \n",
            "EVAL: [700/760] Elapsed 3m 38s (remain 0m 18s) Loss: 0.4970(0.5418) \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4 - avg_train_loss: 0.5098  avg_val_loss: 0.5406  time: 1724s\n",
            "Epoch 4 - Score: 0.8547\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EVAL: [759/760] Elapsed 3m 57s (remain 0m 0s) Loss: 0.4755(0.5406) \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "========== fold: 0 result ==========\n",
            "Score: 0.8550\n",
            "========== fold: 1 training ==========\n",
            "Some weights of the model checkpoint at microsoft/deberta-v3-large were not used when initializing DebertaV2Model: ['mask_predictions.dense.bias', 'mask_predictions.classifier.weight', 'mask_predictions.LayerNorm.weight', 'mask_predictions.LayerNorm.bias', 'lm_predictions.lm_head.bias', 'mask_predictions.classifier.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.dense.weight', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.LayerNorm.bias']\n",
            "- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: [1][0/1519] Elapsed 0m 1s (remain 33m 40s) Loss: 0.7172(0.7172) Grad: 164383.7812  LR: 0.00000042  \n",
            "Epoch: [1][100/1519] Elapsed 1m 38s (remain 23m 9s) Loss: 0.6222(0.6674) Grad: 21369.4336  LR: 0.00000500  \n",
            "Epoch: [1][200/1519] Elapsed 3m 16s (remain 21m 30s) Loss: 0.6063(0.6353) Grad: 30350.5117  LR: 0.00000499  \n",
            "Epoch: [1][300/1519] Elapsed 4m 54s (remain 19m 52s) Loss: 0.6153(0.6216) Grad: 28438.3828  LR: 0.00000497  \n",
            "Epoch: [1][400/1519] Elapsed 6m 32s (remain 18m 14s) Loss: 0.5661(0.6108) Grad: 22435.1758  LR: 0.00000495  \n",
            "Epoch: [1][500/1519] Elapsed 8m 10s (remain 16m 36s) Loss: 0.6000(0.6025) Grad: 17639.4258  LR: 0.00000492  \n",
            "Epoch: [1][600/1519] Elapsed 9m 48s (remain 14m 58s) Loss: 0.6598(0.5967) Grad: 49116.4258  LR: 0.00000488  \n",
            "Epoch: [1][700/1519] Elapsed 11m 25s (remain 13m 20s) Loss: 0.4616(0.5917) Grad: 15122.3467  LR: 0.00000484  \n",
            "Epoch: [1][800/1519] Elapsed 13m 3s (remain 11m 42s) Loss: 0.5515(0.5875) Grad: 19362.2910  LR: 0.00000479  \n",
            "Epoch: [1][900/1519] Elapsed 14m 41s (remain 10m 4s) Loss: 0.4639(0.5820) Grad: 25858.0352  LR: 0.00000474  \n",
            "Epoch: [1][1000/1519] Elapsed 16m 19s (remain 8m 26s) Loss: 0.5647(0.5788) Grad: 11751.6377  LR: 0.00000468  \n",
            "Epoch: [1][1100/1519] Elapsed 17m 57s (remain 6m 48s) Loss: 0.4754(0.5737) Grad: 21984.8672  LR: 0.00000461  \n",
            "Epoch: [1][1200/1519] Elapsed 19m 35s (remain 5m 11s) Loss: 0.5828(0.5715) Grad: 34869.9258  LR: 0.00000454  \n",
            "Epoch: [1][1300/1519] Elapsed 21m 12s (remain 3m 33s) Loss: 0.4552(0.5705) Grad: 16018.0537  LR: 0.00000446  \n",
            "Epoch: [1][1400/1519] Elapsed 22m 50s (remain 1m 55s) Loss: 0.4894(0.5688) Grad: 27012.1836  LR: 0.00000438  \n",
            "Epoch: [1][1500/1519] Elapsed 24m 28s (remain 0m 17s) Loss: 0.5037(0.5667) Grad: 68814.4375  LR: 0.00000429  \n",
            "Epoch: [1][1518/1519] Elapsed 24m 46s (remain 0m 0s) Loss: 0.5366(0.5664) Grad: 19792.2773  LR: 0.00000428  \n",
            "EVAL: [0/760] Elapsed 0m 0s (remain 8m 9s) Loss: 0.5677(0.5677) \n",
            "EVAL: [100/760] Elapsed 0m 31s (remain 3m 27s) Loss: 0.6087(0.5288) \n",
            "EVAL: [200/760] Elapsed 1m 2s (remain 2m 55s) Loss: 0.6397(0.5388) \n",
            "EVAL: [300/760] Elapsed 1m 34s (remain 2m 23s) Loss: 0.6233(0.5405) \n",
            "EVAL: [400/760] Elapsed 2m 5s (remain 1m 52s) Loss: 0.5220(0.5430) \n",
            "EVAL: [500/760] Elapsed 2m 36s (remain 1m 20s) Loss: 0.5320(0.5434) \n",
            "EVAL: [600/760] Elapsed 3m 7s (remain 0m 49s) Loss: 0.5071(0.5414) \n",
            "EVAL: [700/760] Elapsed 3m 38s (remain 0m 18s) Loss: 0.5045(0.5404) \n",
            "EVAL: [759/760] Elapsed 3m 57s (remain 0m 0s) Loss: 0.5359(0.5407) \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1 - avg_train_loss: 0.5664  avg_val_loss: 0.5407  time: 1724s\n",
            "Epoch 1 - Score: 0.8306\n",
            "Epoch 1 - Save Best Score: 0.8306 Model\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: [2][0/1519] Elapsed 0m 1s (remain 33m 56s) Loss: 0.5402(0.5402) Grad: 76098.6406  LR: 0.00000428  \n",
            "Epoch: [2][100/1519] Elapsed 1m 39s (remain 23m 14s) Loss: 0.5334(0.5207) Grad: 41637.2031  LR: 0.00000418  \n",
            "Epoch: [2][200/1519] Elapsed 3m 17s (remain 21m 32s) Loss: 0.5946(0.5247) Grad: 39359.7578  LR: 0.00000408  \n",
            "Epoch: [2][300/1519] Elapsed 4m 54s (remain 19m 53s) Loss: 0.4866(0.5286) Grad: 64602.6836  LR: 0.00000398  \n",
            "Epoch: [2][400/1519] Elapsed 6m 32s (remain 18m 15s) Loss: 0.4966(0.5269) Grad: 54362.0273  LR: 0.00000388  \n",
            "Epoch: [2][500/1519] Elapsed 8m 10s (remain 16m 36s) Loss: 0.5379(0.5257) Grad: 45821.3789  LR: 0.00000377  \n",
            "Epoch: [2][600/1519] Elapsed 9m 48s (remain 14m 58s) Loss: 0.5634(0.5252) Grad: 33875.2617  LR: 0.00000365  \n",
            "Epoch: [2][700/1519] Elapsed 11m 26s (remain 13m 20s) Loss: 0.5366(0.5250) Grad: 26249.4727  LR: 0.00000354  \n",
            "Epoch: [2][800/1519] Elapsed 13m 4s (remain 11m 42s) Loss: 0.5116(0.5255) Grad: 67775.9609  LR: 0.00000342  \n",
            "Epoch: [2][900/1519] Elapsed 14m 42s (remain 10m 4s) Loss: 0.5526(0.5246) Grad: 66276.8516  LR: 0.00000330  \n",
            "Epoch: [2][1000/1519] Elapsed 16m 20s (remain 8m 27s) Loss: 0.4945(0.5247) Grad: 42383.8008  LR: 0.00000317  \n",
            "Epoch: [2][1100/1519] Elapsed 17m 58s (remain 6m 49s) Loss: 0.4267(0.5241) Grad: 137276.3438  LR: 0.00000305  \n",
            "Epoch: [2][1200/1519] Elapsed 19m 35s (remain 5m 11s) Loss: 0.5384(0.5240) Grad: 47357.7227  LR: 0.00000292  \n",
            "Epoch: [2][1300/1519] Elapsed 21m 13s (remain 3m 33s) Loss: 0.5718(0.5234) Grad: 36356.1250  LR: 0.00000279  \n",
            "Epoch: [2][1400/1519] Elapsed 22m 51s (remain 1m 55s) Loss: 0.5270(0.5241) Grad: 33412.4727  LR: 0.00000266  \n",
            "Epoch: [2][1500/1519] Elapsed 24m 29s (remain 0m 17s) Loss: 0.4367(0.5238) Grad: 31280.2207  LR: 0.00000253  \n",
            "Epoch: [2][1518/1519] Elapsed 24m 46s (remain 0m 0s) Loss: 0.5713(0.5238) Grad: 23274.9434  LR: 0.00000251  \n",
            "EVAL: [0/760] Elapsed 0m 0s (remain 7m 7s) Loss: 0.5532(0.5532) \n",
            "EVAL: [100/760] Elapsed 0m 31s (remain 3m 27s) Loss: 0.6297(0.5290) \n",
            "EVAL: [200/760] Elapsed 1m 2s (remain 2m 54s) Loss: 0.6482(0.5392) \n",
            "EVAL: [300/760] Elapsed 1m 34s (remain 2m 23s) Loss: 0.6244(0.5408) \n",
            "EVAL: [400/760] Elapsed 2m 5s (remain 1m 52s) Loss: 0.5123(0.5434) \n",
            "EVAL: [500/760] Elapsed 2m 36s (remain 1m 20s) Loss: 0.5409(0.5434) \n",
            "EVAL: [600/760] Elapsed 3m 7s (remain 0m 49s) Loss: 0.4981(0.5413) \n",
            "EVAL: [700/760] Elapsed 3m 38s (remain 0m 18s) Loss: 0.4778(0.5403) \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2 - avg_train_loss: 0.5238  avg_val_loss: 0.5410  time: 1724s\n",
            "Epoch 2 - Score: 0.8407\n",
            "Epoch 2 - Save Best Score: 0.8407 Model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EVAL: [759/760] Elapsed 3m 57s (remain 0m 0s) Loss: 0.5248(0.5410) \n",
            "Epoch: [3][0/1519] Elapsed 0m 1s (remain 32m 10s) Loss: 0.4847(0.4847) Grad: 97441.2031  LR: 0.00000251  \n",
            "Epoch: [3][100/1519] Elapsed 1m 39s (remain 23m 15s) Loss: 0.6688(0.5202) Grad: 95966.0703  LR: 0.00000238  \n",
            "Epoch: [3][200/1519] Elapsed 3m 17s (remain 21m 33s) Loss: 0.6134(0.5127) Grad: 192462.2344  LR: 0.00000225  \n",
            "Epoch: [3][300/1519] Elapsed 4m 55s (remain 19m 53s) Loss: 0.6096(0.5106) Grad: 141540.6406  LR: 0.00000212  \n",
            "Epoch: [3][400/1519] Elapsed 6m 32s (remain 18m 14s) Loss: 0.5909(0.5118) Grad: 37156.2305  LR: 0.00000199  \n",
            "Epoch: [3][500/1519] Elapsed 8m 10s (remain 16m 36s) Loss: 0.4412(0.5123) Grad: 86005.2266  LR: 0.00000187  \n",
            "Epoch: [3][600/1519] Elapsed 9m 48s (remain 14m 58s) Loss: 0.4851(0.5115) Grad: 82512.8828  LR: 0.00000174  \n",
            "Epoch: [3][700/1519] Elapsed 11m 26s (remain 13m 20s) Loss: 0.5991(0.5108) Grad: 269491.0000  LR: 0.00000162  \n",
            "Epoch: [3][800/1519] Elapsed 13m 4s (remain 11m 42s) Loss: 0.5723(0.5111) Grad: 48923.9336  LR: 0.00000150  \n",
            "Epoch: [3][900/1519] Elapsed 14m 41s (remain 10m 4s) Loss: 0.5100(0.5111) Grad: 35346.8750  LR: 0.00000138  \n",
            "Epoch: [3][1000/1519] Elapsed 16m 19s (remain 8m 27s) Loss: 0.6081(0.5116) Grad: 32350.2578  LR: 0.00000127  \n",
            "Epoch: [3][1100/1519] Elapsed 17m 57s (remain 6m 49s) Loss: 0.5453(0.5129) Grad: 52561.9180  LR: 0.00000116  \n",
            "Epoch: [3][1200/1519] Elapsed 19m 35s (remain 5m 11s) Loss: 0.5390(0.5132) Grad: 124437.1562  LR: 0.00000105  \n",
            "Epoch: [3][1300/1519] Elapsed 21m 13s (remain 3m 33s) Loss: 0.4710(0.5144) Grad: 47326.3320  LR: 0.00000095  \n",
            "Epoch: [3][1400/1519] Elapsed 22m 50s (remain 1m 55s) Loss: 0.5485(0.5151) Grad: 39903.9648  LR: 0.00000085  \n",
            "Epoch: [3][1500/1519] Elapsed 24m 28s (remain 0m 17s) Loss: 0.4973(0.5158) Grad: 106946.6250  LR: 0.00000075  \n",
            "Epoch: [3][1518/1519] Elapsed 24m 46s (remain 0m 0s) Loss: 0.5058(0.5157) Grad: 24732.6172  LR: 0.00000074  \n",
            "EVAL: [0/760] Elapsed 0m 0s (remain 7m 3s) Loss: 0.5388(0.5388) \n",
            "EVAL: [100/760] Elapsed 0m 31s (remain 3m 26s) Loss: 0.6303(0.5301) \n",
            "EVAL: [200/760] Elapsed 1m 2s (remain 2m 54s) Loss: 0.6621(0.5410) \n",
            "EVAL: [300/760] Elapsed 1m 33s (remain 2m 23s) Loss: 0.6240(0.5425) \n",
            "EVAL: [400/760] Elapsed 2m 5s (remain 1m 51s) Loss: 0.5045(0.5459) \n",
            "EVAL: [500/760] Elapsed 2m 36s (remain 1m 20s) Loss: 0.5297(0.5458) \n",
            "EVAL: [600/760] Elapsed 3m 7s (remain 0m 49s) Loss: 0.5004(0.5437) \n",
            "EVAL: [700/760] Elapsed 3m 38s (remain 0m 18s) Loss: 0.4836(0.5427) \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3 - avg_train_loss: 0.5157  avg_val_loss: 0.5434  time: 1723s\n",
            "Epoch 3 - Score: 0.8428\n",
            "Epoch 3 - Save Best Score: 0.8428 Model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EVAL: [759/760] Elapsed 3m 56s (remain 0m 0s) Loss: 0.5246(0.5434) \n",
            "Epoch: [4][0/1519] Elapsed 0m 1s (remain 32m 0s) Loss: 0.4861(0.4861) Grad: 134993.5312  LR: 0.00000074  \n",
            "Epoch: [4][100/1519] Elapsed 1m 39s (remain 23m 13s) Loss: 0.3810(0.5168) Grad: 245621.4375  LR: 0.00000065  \n",
            "Epoch: [4][200/1519] Elapsed 3m 16s (remain 21m 31s) Loss: 0.5938(0.5124) Grad: 79981.3359  LR: 0.00000056  \n",
            "Epoch: [4][300/1519] Elapsed 4m 54s (remain 19m 52s) Loss: 0.5764(0.5120) Grad: 134127.4375  LR: 0.00000048  \n",
            "Epoch: [4][400/1519] Elapsed 6m 32s (remain 18m 14s) Loss: 0.5952(0.5128) Grad: 145128.2969  LR: 0.00000041  \n",
            "Epoch: [4][500/1519] Elapsed 8m 10s (remain 16m 36s) Loss: 0.3745(0.5131) Grad: 141243.0469  LR: 0.00000034  \n",
            "Epoch: [4][600/1519] Elapsed 9m 48s (remain 14m 58s) Loss: 0.4834(0.5115) Grad: 75441.3750  LR: 0.00000028  \n",
            "Epoch: [4][700/1519] Elapsed 11m 25s (remain 13m 20s) Loss: 0.5541(0.5133) Grad: 154188.9375  LR: 0.00000022  \n",
            "Epoch: [4][800/1519] Elapsed 13m 3s (remain 11m 42s) Loss: 0.5556(0.5131) Grad: 77838.0078  LR: 0.00000017  \n",
            "Epoch: [4][900/1519] Elapsed 14m 41s (remain 10m 4s) Loss: 0.4971(0.5103) Grad: 47127.7266  LR: 0.00000013  \n",
            "Epoch: [4][1000/1519] Elapsed 16m 19s (remain 8m 26s) Loss: 0.6358(0.5108) Grad: 188702.8281  LR: 0.00000009  \n",
            "Epoch: [4][1100/1519] Elapsed 17m 56s (remain 6m 48s) Loss: 0.5070(0.5105) Grad: 32553.6055  LR: 0.00000006  \n",
            "Epoch: [4][1200/1519] Elapsed 19m 34s (remain 5m 11s) Loss: 0.4754(0.5104) Grad: 78318.3125  LR: 0.00000003  \n",
            "Epoch: [4][1300/1519] Elapsed 21m 12s (remain 3m 33s) Loss: 0.4799(0.5109) Grad: 42222.5391  LR: 0.00000002  \n",
            "Epoch: [4][1400/1519] Elapsed 22m 50s (remain 1m 55s) Loss: 0.5397(0.5110) Grad: 77098.1562  LR: 0.00000000  \n",
            "Epoch: [4][1500/1519] Elapsed 24m 27s (remain 0m 17s) Loss: 0.4893(0.5107) Grad: 49140.8008  LR: 0.00000000  \n",
            "Epoch: [4][1518/1519] Elapsed 24m 45s (remain 0m 0s) Loss: 0.5137(0.5108) Grad: 42783.1016  LR: 0.00000000  \n",
            "EVAL: [0/760] Elapsed 0m 0s (remain 7m 18s) Loss: 0.5451(0.5451) \n",
            "EVAL: [100/760] Elapsed 0m 31s (remain 3m 26s) Loss: 0.6220(0.5303) \n",
            "EVAL: [200/760] Elapsed 1m 2s (remain 2m 54s) Loss: 0.6533(0.5414) \n",
            "EVAL: [300/760] Elapsed 1m 33s (remain 2m 23s) Loss: 0.6199(0.5429) \n",
            "EVAL: [400/760] Elapsed 2m 5s (remain 1m 52s) Loss: 0.5003(0.5460) \n",
            "EVAL: [500/760] Elapsed 2m 36s (remain 1m 20s) Loss: 0.5321(0.5460) \n",
            "EVAL: [600/760] Elapsed 3m 7s (remain 0m 49s) Loss: 0.5003(0.5440) \n",
            "EVAL: [700/760] Elapsed 3m 38s (remain 0m 18s) Loss: 0.4824(0.5428) \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4 - avg_train_loss: 0.5108  avg_val_loss: 0.5435  time: 1723s\n",
            "Epoch 4 - Score: 0.8436\n",
            "Epoch 4 - Save Best Score: 0.8436 Model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EVAL: [759/760] Elapsed 3m 56s (remain 0m 0s) Loss: 0.5260(0.5435) \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "========== fold: 1 result ==========\n",
            "Score: 0.8436\n",
            "========== fold: 2 training ==========\n",
            "Some weights of the model checkpoint at microsoft/deberta-v3-large were not used when initializing DebertaV2Model: ['mask_predictions.dense.bias', 'mask_predictions.classifier.weight', 'mask_predictions.LayerNorm.weight', 'mask_predictions.LayerNorm.bias', 'lm_predictions.lm_head.bias', 'mask_predictions.classifier.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.dense.weight', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.LayerNorm.bias']\n",
            "- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: [1][0/1519] Elapsed 0m 1s (remain 33m 11s) Loss: 0.6893(0.6893) Grad: inf  LR: 0.00000042  \n",
            "Epoch: [1][100/1519] Elapsed 1m 39s (remain 23m 13s) Loss: 0.6366(0.6519) Grad: 40591.2930  LR: 0.00000500  \n",
            "Epoch: [1][200/1519] Elapsed 3m 17s (remain 21m 32s) Loss: 0.6351(0.6286) Grad: 45013.1758  LR: 0.00000499  \n",
            "Epoch: [1][300/1519] Elapsed 4m 54s (remain 19m 52s) Loss: 0.5509(0.6119) Grad: 30291.1523  LR: 0.00000497  \n",
            "Epoch: [1][400/1519] Elapsed 6m 32s (remain 18m 14s) Loss: 0.5445(0.6001) Grad: 43242.7383  LR: 0.00000495  \n",
            "Epoch: [1][500/1519] Elapsed 8m 10s (remain 16m 35s) Loss: 0.4803(0.5919) Grad: 44599.9258  LR: 0.00000492  \n",
            "Epoch: [1][600/1519] Elapsed 9m 47s (remain 14m 58s) Loss: 0.5726(0.5881) Grad: 30051.2422  LR: 0.00000488  \n",
            "Epoch: [1][700/1519] Elapsed 11m 25s (remain 13m 20s) Loss: 0.5804(0.5845) Grad: 26552.2637  LR: 0.00000484  \n",
            "Epoch: [1][800/1519] Elapsed 13m 3s (remain 11m 42s) Loss: 0.5342(0.5801) Grad: 24084.0625  LR: 0.00000479  \n",
            "Epoch: [1][900/1519] Elapsed 14m 41s (remain 10m 4s) Loss: 0.4749(0.5759) Grad: 29727.2871  LR: 0.00000474  \n",
            "Epoch: [1][1000/1519] Elapsed 16m 18s (remain 8m 26s) Loss: 0.4200(0.5733) Grad: 37560.9844  LR: 0.00000468  \n",
            "Epoch: [1][1100/1519] Elapsed 17m 56s (remain 6m 48s) Loss: 0.4939(0.5711) Grad: 24005.5352  LR: 0.00000461  \n",
            "Epoch: [1][1200/1519] Elapsed 19m 34s (remain 5m 11s) Loss: 0.5791(0.5697) Grad: 28169.4688  LR: 0.00000454  \n",
            "Epoch: [1][1300/1519] Elapsed 21m 12s (remain 3m 33s) Loss: 0.5391(0.5669) Grad: 15556.5527  LR: 0.00000446  \n",
            "Epoch: [1][1400/1519] Elapsed 22m 50s (remain 1m 55s) Loss: 0.5416(0.5663) Grad: 23146.3438  LR: 0.00000438  \n",
            "Epoch: [1][1500/1519] Elapsed 24m 27s (remain 0m 17s) Loss: 0.4704(0.5646) Grad: 9590.9316  LR: 0.00000429  \n",
            "Epoch: [1][1518/1519] Elapsed 24m 45s (remain 0m 0s) Loss: 0.5705(0.5648) Grad: 1642.4442  LR: 0.00000428  \n",
            "EVAL: [0/760] Elapsed 0m 0s (remain 7m 40s) Loss: 0.5528(0.5528) \n",
            "EVAL: [100/760] Elapsed 0m 31s (remain 3m 27s) Loss: 0.5831(0.5477) \n",
            "EVAL: [200/760] Elapsed 1m 2s (remain 2m 54s) Loss: 0.6221(0.5549) \n",
            "EVAL: [300/760] Elapsed 1m 34s (remain 2m 23s) Loss: 0.5429(0.5562) \n",
            "EVAL: [400/760] Elapsed 2m 5s (remain 1m 52s) Loss: 0.6727(0.5545) \n",
            "EVAL: [500/760] Elapsed 2m 36s (remain 1m 20s) Loss: 0.5279(0.5537) \n",
            "EVAL: [600/760] Elapsed 3m 7s (remain 0m 49s) Loss: 0.6287(0.5534) \n",
            "EVAL: [700/760] Elapsed 3m 38s (remain 0m 18s) Loss: 0.5985(0.5531) \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1 - avg_train_loss: 0.5648  avg_val_loss: 0.5529  time: 1723s\n",
            "Epoch 1 - Score: 0.8179\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EVAL: [759/760] Elapsed 3m 56s (remain 0m 0s) Loss: 0.4348(0.5529) \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1 - Save Best Score: 0.8179 Model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: [2][0/1519] Elapsed 0m 1s (remain 33m 53s) Loss: 0.6030(0.6030) Grad: 166388.3438  LR: 0.00000428  \n",
            "Epoch: [2][100/1519] Elapsed 1m 39s (remain 23m 12s) Loss: 0.6599(0.5668) Grad: 61590.2695  LR: 0.00000418  \n",
            "Epoch: [2][200/1519] Elapsed 3m 16s (remain 21m 31s) Loss: 0.5965(0.5480) Grad: 75613.1016  LR: 0.00000408  \n",
            "Epoch: [2][300/1519] Elapsed 4m 54s (remain 19m 52s) Loss: 0.5540(0.5434) Grad: 32087.5898  LR: 0.00000398  \n",
            "Epoch: [2][400/1519] Elapsed 6m 32s (remain 18m 14s) Loss: 0.4208(0.5393) Grad: 54320.6016  LR: 0.00000388  \n",
            "Epoch: [2][500/1519] Elapsed 8m 10s (remain 16m 36s) Loss: 0.5654(0.5372) Grad: 49439.7734  LR: 0.00000377  \n",
            "Epoch: [2][600/1519] Elapsed 9m 48s (remain 14m 58s) Loss: 0.5863(0.5362) Grad: 26487.8789  LR: 0.00000365  \n",
            "Epoch: [2][700/1519] Elapsed 11m 25s (remain 13m 20s) Loss: 0.5006(0.5341) Grad: 15872.7832  LR: 0.00000354  \n",
            "Epoch: [2][800/1519] Elapsed 13m 3s (remain 11m 42s) Loss: 0.5142(0.5340) Grad: 19731.9316  LR: 0.00000342  \n",
            "Epoch: [2][900/1519] Elapsed 14m 41s (remain 10m 4s) Loss: 0.5023(0.5322) Grad: 59539.2695  LR: 0.00000330  \n",
            "Epoch: [2][1000/1519] Elapsed 16m 19s (remain 8m 26s) Loss: 0.5247(0.5310) Grad: 28286.0586  LR: 0.00000317  \n",
            "Epoch: [2][1100/1519] Elapsed 17m 57s (remain 6m 48s) Loss: 0.5148(0.5297) Grad: 10878.7236  LR: 0.00000305  \n",
            "Epoch: [2][1200/1519] Elapsed 19m 34s (remain 5m 11s) Loss: 0.5371(0.5287) Grad: 38899.5430  LR: 0.00000292  \n",
            "Epoch: [2][1300/1519] Elapsed 21m 12s (remain 3m 33s) Loss: 0.5746(0.5293) Grad: 14649.3574  LR: 0.00000279  \n",
            "Epoch: [2][1400/1519] Elapsed 22m 50s (remain 1m 55s) Loss: 0.5002(0.5282) Grad: 14997.8076  LR: 0.00000266  \n",
            "Epoch: [2][1500/1519] Elapsed 24m 28s (remain 0m 17s) Loss: 0.4311(0.5275) Grad: 30348.5469  LR: 0.00000253  \n",
            "Epoch: [2][1518/1519] Elapsed 24m 45s (remain 0m 0s) Loss: 0.5425(0.5276) Grad: 21247.8887  LR: 0.00000251  \n",
            "EVAL: [0/760] Elapsed 0m 0s (remain 7m 14s) Loss: 0.5223(0.5223) \n",
            "EVAL: [100/760] Elapsed 0m 31s (remain 3m 27s) Loss: 0.5759(0.5398) \n",
            "EVAL: [200/760] Elapsed 1m 2s (remain 2m 54s) Loss: 0.6539(0.5444) \n",
            "EVAL: [300/760] Elapsed 1m 33s (remain 2m 23s) Loss: 0.5062(0.5452) \n",
            "EVAL: [400/760] Elapsed 2m 5s (remain 1m 52s) Loss: 0.6234(0.5425) \n",
            "EVAL: [500/760] Elapsed 2m 36s (remain 1m 20s) Loss: 0.5163(0.5421) \n",
            "EVAL: [600/760] Elapsed 3m 7s (remain 0m 49s) Loss: 0.5960(0.5417) \n",
            "EVAL: [700/760] Elapsed 3m 38s (remain 0m 18s) Loss: 0.5969(0.5411) \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2 - avg_train_loss: 0.5276  avg_val_loss: 0.5415  time: 1723s\n",
            "Epoch 2 - Score: 0.8425\n",
            "Epoch 2 - Save Best Score: 0.8425 Model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EVAL: [759/760] Elapsed 3m 56s (remain 0m 0s) Loss: 0.4049(0.5415) \n",
            "Epoch: [3][0/1519] Elapsed 0m 1s (remain 31m 20s) Loss: 0.5097(0.5097) Grad: 186348.1562  LR: 0.00000251  \n",
            "Epoch: [3][100/1519] Elapsed 1m 39s (remain 23m 13s) Loss: 0.5797(0.5153) Grad: 66838.4141  LR: 0.00000238  \n",
            "Epoch: [3][200/1519] Elapsed 3m 17s (remain 21m 31s) Loss: 0.5639(0.5134) Grad: 53766.5820  LR: 0.00000225  \n",
            "Epoch: [3][300/1519] Elapsed 4m 54s (remain 19m 53s) Loss: 0.5569(0.5131) Grad: 151465.7969  LR: 0.00000212  \n",
            "Epoch: [3][400/1519] Elapsed 6m 32s (remain 18m 14s) Loss: 0.5505(0.5139) Grad: 78706.0312  LR: 0.00000199  \n",
            "Epoch: [3][500/1519] Elapsed 8m 10s (remain 16m 36s) Loss: 0.5466(0.5138) Grad: 23043.2734  LR: 0.00000187  \n",
            "Epoch: [3][600/1519] Elapsed 9m 48s (remain 14m 58s) Loss: 0.4982(0.5146) Grad: 77011.8125  LR: 0.00000174  \n",
            "Epoch: [3][700/1519] Elapsed 11m 25s (remain 13m 20s) Loss: 0.5518(0.5153) Grad: 39348.2812  LR: 0.00000162  \n",
            "Epoch: [3][800/1519] Elapsed 13m 3s (remain 11m 42s) Loss: 0.5514(0.5146) Grad: 40872.8008  LR: 0.00000150  \n",
            "Epoch: [3][900/1519] Elapsed 14m 41s (remain 10m 4s) Loss: 0.5851(0.5145) Grad: 28158.9023  LR: 0.00000138  \n",
            "Epoch: [3][1000/1519] Elapsed 16m 19s (remain 8m 26s) Loss: 0.5699(0.5150) Grad: 37250.5273  LR: 0.00000127  \n",
            "Epoch: [3][1100/1519] Elapsed 17m 57s (remain 6m 48s) Loss: 0.5713(0.5150) Grad: 51225.8789  LR: 0.00000116  \n",
            "Epoch: [3][1200/1519] Elapsed 19m 35s (remain 5m 11s) Loss: 0.5635(0.5152) Grad: 32544.8652  LR: 0.00000105  \n",
            "Epoch: [3][1300/1519] Elapsed 21m 12s (remain 3m 33s) Loss: 0.5242(0.5145) Grad: 129902.0938  LR: 0.00000095  \n",
            "Epoch: [3][1400/1519] Elapsed 22m 50s (remain 1m 55s) Loss: 0.5004(0.5141) Grad: 281741.7188  LR: 0.00000085  \n",
            "Epoch: [3][1500/1519] Elapsed 24m 28s (remain 0m 17s) Loss: 0.5144(0.5143) Grad: 24007.7305  LR: 0.00000075  \n",
            "Epoch: [3][1518/1519] Elapsed 24m 45s (remain 0m 0s) Loss: 0.6553(0.5145) Grad: 27292.0176  LR: 0.00000074  \n",
            "EVAL: [0/760] Elapsed 0m 0s (remain 7m 5s) Loss: 0.5245(0.5245) \n",
            "EVAL: [100/760] Elapsed 0m 31s (remain 3m 26s) Loss: 0.5738(0.5379) \n",
            "EVAL: [200/760] Elapsed 1m 2s (remain 2m 54s) Loss: 0.6401(0.5420) \n",
            "EVAL: [300/760] Elapsed 1m 33s (remain 2m 23s) Loss: 0.5171(0.5432) \n",
            "EVAL: [400/760] Elapsed 2m 5s (remain 1m 52s) Loss: 0.6124(0.5408) \n",
            "EVAL: [500/760] Elapsed 2m 36s (remain 1m 20s) Loss: 0.5129(0.5404) \n",
            "EVAL: [600/760] Elapsed 3m 7s (remain 0m 49s) Loss: 0.5997(0.5404) \n",
            "EVAL: [700/760] Elapsed 3m 38s (remain 0m 18s) Loss: 0.5840(0.5400) \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3 - avg_train_loss: 0.5145  avg_val_loss: 0.5403  time: 1723s\n",
            "Epoch 3 - Score: 0.8484\n",
            "Epoch 3 - Save Best Score: 0.8484 Model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EVAL: [759/760] Elapsed 3m 56s (remain 0m 0s) Loss: 0.4025(0.5403) \n",
            "Epoch: [4][0/1519] Elapsed 0m 1s (remain 34m 20s) Loss: 0.5443(0.5443) Grad: 476317.6562  LR: 0.00000074  \n",
            "Epoch: [4][100/1519] Elapsed 1m 39s (remain 23m 15s) Loss: 0.5103(0.5070) Grad: 113287.7891  LR: 0.00000065  \n",
            "Epoch: [4][200/1519] Elapsed 3m 17s (remain 21m 32s) Loss: 0.5750(0.5077) Grad: 88112.2031  LR: 0.00000056  \n",
            "Epoch: [4][300/1519] Elapsed 4m 54s (remain 19m 53s) Loss: 0.4039(0.5075) Grad: 48292.7969  LR: 0.00000048  \n",
            "Epoch: [4][400/1519] Elapsed 6m 32s (remain 18m 14s) Loss: 0.5434(0.5078) Grad: 32627.1406  LR: 0.00000041  \n",
            "Epoch: [4][500/1519] Elapsed 8m 10s (remain 16m 36s) Loss: 0.4553(0.5093) Grad: 92284.2969  LR: 0.00000034  \n",
            "Epoch: [4][600/1519] Elapsed 9m 48s (remain 14m 58s) Loss: 0.6186(0.5096) Grad: 21272.0762  LR: 0.00000028  \n",
            "Epoch: [4][700/1519] Elapsed 11m 26s (remain 13m 20s) Loss: 0.5411(0.5098) Grad: 37655.6602  LR: 0.00000022  \n",
            "Epoch: [4][800/1519] Elapsed 13m 3s (remain 11m 42s) Loss: 0.4883(0.5088) Grad: 48202.4609  LR: 0.00000017  \n",
            "Epoch: [4][900/1519] Elapsed 14m 41s (remain 10m 4s) Loss: 0.4146(0.5080) Grad: 18683.7852  LR: 0.00000013  \n",
            "Epoch: [4][1000/1519] Elapsed 16m 19s (remain 8m 26s) Loss: 0.5068(0.5083) Grad: 12830.1367  LR: 0.00000009  \n",
            "Epoch: [4][1100/1519] Elapsed 17m 57s (remain 6m 48s) Loss: 0.4459(0.5093) Grad: 64551.3711  LR: 0.00000006  \n",
            "Epoch: [4][1200/1519] Elapsed 19m 34s (remain 5m 11s) Loss: 0.4933(0.5095) Grad: 17424.8613  LR: 0.00000003  \n",
            "Epoch: [4][1300/1519] Elapsed 21m 12s (remain 3m 33s) Loss: 0.6761(0.5100) Grad: 70100.2031  LR: 0.00000002  \n",
            "Epoch: [4][1400/1519] Elapsed 22m 50s (remain 1m 55s) Loss: 0.5356(0.5107) Grad: 20848.9766  LR: 0.00000000  \n",
            "Epoch: [4][1500/1519] Elapsed 24m 28s (remain 0m 17s) Loss: 0.6283(0.5109) Grad: 16278.0195  LR: 0.00000000  \n",
            "Epoch: [4][1518/1519] Elapsed 24m 45s (remain 0m 0s) Loss: 0.5966(0.5109) Grad: 42182.9844  LR: 0.00000000  \n",
            "EVAL: [0/760] Elapsed 0m 0s (remain 7m 23s) Loss: 0.5236(0.5236) \n",
            "EVAL: [100/760] Elapsed 0m 31s (remain 3m 27s) Loss: 0.5751(0.5396) \n",
            "EVAL: [200/760] Elapsed 1m 2s (remain 2m 54s) Loss: 0.6444(0.5437) \n",
            "EVAL: [300/760] Elapsed 1m 34s (remain 2m 23s) Loss: 0.5140(0.5447) \n",
            "EVAL: [400/760] Elapsed 2m 5s (remain 1m 52s) Loss: 0.6117(0.5423) \n",
            "EVAL: [500/760] Elapsed 2m 36s (remain 1m 20s) Loss: 0.5156(0.5419) \n",
            "EVAL: [600/760] Elapsed 3m 7s (remain 0m 49s) Loss: 0.6012(0.5420) \n",
            "EVAL: [700/760] Elapsed 3m 38s (remain 0m 18s) Loss: 0.5863(0.5415) \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4 - avg_train_loss: 0.5109  avg_val_loss: 0.5418  time: 1723s\n",
            "Epoch 4 - Score: 0.8484\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EVAL: [759/760] Elapsed 3m 56s (remain 0m 0s) Loss: 0.3992(0.5418) \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "========== fold: 2 result ==========\n",
            "Score: 0.8484\n",
            "========== CV ==========\n",
            "Score: 0.8481\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8345c0000e644364bbfe3f2d8f813e15"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>[fold0] avg_train_loss</td><td>█▃▂▁</td></tr><tr><td>[fold0] avg_val_loss</td><td>█▂▁▅</td></tr><tr><td>[fold0] epoch</td><td>▁▃▆█</td></tr><tr><td>[fold0] loss</td><td>█▇▇▃▇▅▆▅▇▅▁▅▇▃▄▄▃▇▂▃▇▆▃▆▄▅▄▄▂▆▆▅▂▄▁▄▄▆▄▅</td></tr><tr><td>[fold0] lr</td><td>███████▇▇▇▇▇▇▆▆▆▅▅▅▅▄▄▄▄▃▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁</td></tr><tr><td>[fold0] score</td><td>▁▇██</td></tr><tr><td>[fold1] avg_train_loss</td><td>█▃▂▁</td></tr><tr><td>[fold1] avg_val_loss</td><td>▁▂██</td></tr><tr><td>[fold1] epoch</td><td>▁▃▆█</td></tr><tr><td>[fold1] loss</td><td>█▆▄▆▅▅▆▄▄▆▆▄▄▅▆▅▅▆▇▆▄▃▄▅▄▅▄▄█▄▇▆▆▄▆▆▂▅▄▁</td></tr><tr><td>[fold1] lr</td><td>███████▇▇▇▇▇▇▆▆▆▅▅▅▅▄▄▄▄▃▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁</td></tr><tr><td>[fold1] score</td><td>▁▆██</td></tr><tr><td>[fold2] avg_train_loss</td><td>█▃▁▁</td></tr><tr><td>[fold2] avg_val_loss</td><td>█▂▁▂</td></tr><tr><td>[fold2] epoch</td><td>▁▃▆█</td></tr><tr><td>[fold2] loss</td><td>▆▅▅▄▆▁▃▆▃▅█▄▅▃▆▃▇▂▅▃▄▃▂▄▅▂▁▂▃▃▄▅▅▆▂▅▂▄▄▃</td></tr><tr><td>[fold2] lr</td><td>███████▇▇▇▇▇▇▆▆▆▅▅▅▅▄▄▄▄▃▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁</td></tr><tr><td>[fold2] score</td><td>▁▇██</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>[fold0] avg_train_loss</td><td>0.50984</td></tr><tr><td>[fold0] avg_val_loss</td><td>0.54058</td></tr><tr><td>[fold0] epoch</td><td>4</td></tr><tr><td>[fold0] loss</td><td>0.5083</td></tr><tr><td>[fold0] lr</td><td>0.0</td></tr><tr><td>[fold0] score</td><td>0.85471</td></tr><tr><td>[fold1] avg_train_loss</td><td>0.51077</td></tr><tr><td>[fold1] avg_val_loss</td><td>0.54353</td></tr><tr><td>[fold1] epoch</td><td>4</td></tr><tr><td>[fold1] loss</td><td>0.51366</td></tr><tr><td>[fold1] lr</td><td>0.0</td></tr><tr><td>[fold1] score</td><td>0.84357</td></tr><tr><td>[fold2] avg_train_loss</td><td>0.51088</td></tr><tr><td>[fold2] avg_val_loss</td><td>0.5418</td></tr><tr><td>[fold2] epoch</td><td>4</td></tr><tr><td>[fold2] loss</td><td>0.5966</td></tr><tr><td>[fold2] lr</td><td>0.0</td></tr><tr><td>[fold2] score</td><td>0.8484</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Synced <strong style=\"color:#cdcd00\">microsoft/deberta-v3-large</strong>: <a href=\"https://wandb.ai/anony-mouse-222846/PPPM-Public/runs/30ouob32?apiKey=5cbad29da28922738e391eea01705005e1fa3ffb\" target=\"_blank\">https://wandb.ai/anony-mouse-222846/PPPM-Public/runs/30ouob32?apiKey=5cbad29da28922738e391eea01705005e1fa3ffb</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20220324_084002-30ouob32/logs</code>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Predictions"
      ],
      "metadata": {
        "id": "8tkroEJSf28q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ap4cKROtEOjs"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Todos : create many sample finetuned for different groups of context variable"
      ],
      "metadata": {
        "id": "pfHB-2CobRrm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "7AYJaVVpbWmu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}